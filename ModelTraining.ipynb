{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a08b04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip show numpy\n",
    "!pip install keras\n",
    "!pip install protobuf\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2cd2107",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from numpy import loadtxt\n",
    "\n",
    "#Read as csv\n",
    "#skip bad lines instead of using bad data\n",
    "content = pd.read_csv('data-file.csv', sep='#', on_bad_lines='skip')\n",
    "\n",
    "#Get the max ammount of words in one comment\n",
    "print(\"Measuring the comment with the most words...\")\n",
    "\n",
    "max_comment = max(content['reviewText'], key=len)\n",
    "print(max_comment)\n",
    "\n",
    "print(\"Biggest comment has number of words:\")\n",
    "max_comment_char_count = len(max_comment)\n",
    "print(max_comment_char_count)\n",
    "\n",
    "print(\"CSV has this many lines..\")\n",
    "print(len(content))\n",
    "\n",
    "print(\"Train data..\")\n",
    "train_data = content[:64] #only the first x comments\n",
    "print(train_data)\n",
    "\n",
    "print(\"Test data..\")\n",
    "test_data = content[-64:] #only the last x comments\n",
    "print(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4f7c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare train and test data with content and flag(x, y)\n",
    "train_y = train_data['reviewText']\n",
    "print(train_y)\n",
    "train_x = train_data['labelPos']\n",
    "print(train_x)\n",
    "\n",
    "test_y = test_data['reviewText']\n",
    "print(test_y)\n",
    "test_x = test_data['labelPos']\n",
    "print(test_x)\n",
    "\n",
    "print(\"Train-Data\")\n",
    "print(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d8b109",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(test_x))\n",
    "print(len(test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e49515",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocess with tokenization\n",
    "#max words for vocab\n",
    "num_words = 1000\n",
    "\n",
    "#set out of vocab token\n",
    "oov_token = '<UNK>'\n",
    "\n",
    "#set pad and trunc-type\n",
    "pad_type = 'post'\n",
    "trunc_type = 'post'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8decee37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create tokenizer\n",
    "tokenizer = Tokenizer(num_words=num_words, oov_token=oov_token)\n",
    "tokenizer.fit_on_texts(train_y)\n",
    "\n",
    "#create word index\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "#encode train data\n",
    "train_sequences = tokenizer.texts_to_sequences(train_y)\n",
    "\n",
    "#Get max training sequence length\n",
    "maxlen = max([len(x) for x in train_sequences])\n",
    "\n",
    "#Pad the training sequences\n",
    "train_padded = pad_sequences(train_sequences, padding=pad_type, truncating=trunc_type, maxlen=maxlen)\n",
    "\n",
    "print(train_sequences)\n",
    "print(train_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b00c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "#vectorize train data\n",
    "def vectorize(sequences, dimension = 137):\n",
    "    results = np.zeros((len(sequences), dimension))\n",
    "    for i, sequence in enumerate(sequences):\n",
    "        results[i, sequence] = 1\n",
    "    return results\n",
    "\n",
    "train_x = vectorize(train_x).astype(\"int64\")\n",
    "train_y = np.array(train_padded).astype(\"float64\")\n",
    "\n",
    "test_x = vectorize(test_x).astype(\"int64\")\n",
    "test_y = np.array(train_padded).astype(\"float64\")\n",
    "\n",
    "print(\"Testdata:Y\")\n",
    "print(test_y)\n",
    "print(\"Testdata:X(Labels)\")\n",
    "print(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d9452f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#output of results\n",
    "print(\"Word index:\\n\", word_index)\n",
    "print(\"Training sequences:\\n\", train_sequences)\n",
    "print(\"Padded training sequences:\\n\", train_padded)\n",
    "print(\"Padded training shape:\", train_padded.shape)\n",
    "print(\"Training sequences data type:\", type(train_sequences))\n",
    "print(\"Padded Training sequences data type:\", type(train_padded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d08c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenize test data\n",
    "test_sequences = tokenizer.texts_to_sequences(test_data['reviewText'])\n",
    "test_padded = pad_sequences(test_sequences, padding=pad_type, truncating=trunc_type, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b7f0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Testing sequences:\\n\", test_sequences)\n",
    "print(\"\\nPadded testing sequences:\\n\", test_padded)\n",
    "print(\"\\nPadded testing shape:\",test_padded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e264ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3075d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#build model\n",
    "model = models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118d6759",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add layers to the model\n",
    "# Input layer\n",
    "model.add(layers.Dense(10, activation = \"relu\", input_shape=(2, 137)))\n",
    "# Hidden layers\n",
    "model.add(layers.Dropout(0.3, noise_shape=None, seed=None))\n",
    "model.add(layers.Dense(10, activation = \"tanh\"))\n",
    "# Output layer\n",
    "model.add(layers.Dense(1, activation = \"swish\"))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "544ebedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#compile model and prepare for training\n",
    "model.compile(\n",
    "optimizer = \"ftrl\",\n",
    "loss = \"binary_crossentropy\",\n",
    "metrics = [\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a53502",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Traindata shape..\")\n",
    "print(len(train_x))\n",
    "print(len(train_y))\n",
    "\n",
    "print(\"Testdata shape..\")\n",
    "print(len(test_x))\n",
    "print(len(test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308d7f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define batch size and epochs\n",
    "results = model.fit(\n",
    "train_x, train_y,\n",
    "epochs= 2,\n",
    "batch_size = 2,\n",
    "validation_data = (test_x, test_y)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4ba844",
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluate model accuracy\n",
    "scores = model.evaluate(test_x, test_y, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880e8df4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
